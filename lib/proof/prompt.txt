I have this bit of rust reading a bincoded struct with a filecoin proof

use bincode::deserialize;
    let commit_phase1_output = {
        let mut commit_phase1_output_path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        commit_phase1_output_path.push(COMMIT_PHASE1_OUTPUT_FILE);
        println!("*** Restoring commit phase1 output file");
        let commit_phase1_output_bytes = read(&commit_phase1_output_path)
            .with_context(|| {
                format!(
                    "couldn't read file commit_phase1_output_path={:?}",
                    commit_phase1_output_path
                )
            })
            .unwrap();
        println!(
            "commit_phase1_output_bytes len {}",
            commit_phase1_output_bytes.len()
        );

        let res: SealCommitPhase1Output<SectorShape32GiB> =
            deserialize(&commit_phase1_output_bytes).unwrap();
        res
    };

Then the bit of c++ that writes it
// Copyright Supranational LLC

// Filecoin Sealing Commit 1 (C1) operation

#include <cstdint>             // uint*
#include <cstring>             // memcpy
#include <fstream>             // file read
#include <fcntl.h>             // file open
#include <unistd.h>            // file close
#include <sys/mman.h>          // mapping
#include <sys/stat.h>          // file stats
#include <iostream>            // printing
#include <iomanip>             // printing
#include <cassert>             // assertions
#include <cmath>               // log2
#include <gmp.h>               // gmp for challenge modulo operation
#include <vector>              //

#include <ff/bls12-381.hpp>
#include "tree_d_cc_nodes.h"
#include "../poseidon/poseidon.hpp"
#include "../sha/sha_functions.hpp"
#include "../util/mmap_t.hpp"

#include "path_element.hpp"
#include "tree_proof.hpp"
#include "column_proof.hpp"
#include "label_proof.hpp"
#include "challenge.hpp"

template<class C>
class C1 {
 public:
  C1(streaming_node_reader_t<C>& reader, size_t sector_slot);
  ~C1();

  void SetReplicaID(const node_t* replica_id) { replica_id_ = replica_id; }
  void SetTicket(const node_t* ticket) { ticket_ = ticket; }

  void DeriveChallenges(const uint8_t* seed);

  void SetTreeRBufs(const char* tree_r_cache, const char* file_prefix,
                    bool include_slot = false) {
    size_t num_files = C::GetNumTreeRCFiles();
    tree_r_bufs_.resize(num_files);
    SetTreeBufs(&tree_r_bufs_[0], tree_r_cache,
                file_prefix, num_files, include_slot);
  }

  void SetTreeCBufs(const char* tree_c_cache, const char* file_prefix,
                    bool include_slot = false) {
    size_t num_files = C::GetNumTreeRCFiles();
    tree_c_bufs_.resize(num_files);
    SetTreeBufs(&tree_c_bufs_[0], tree_c_cache,
                file_prefix, num_files, include_slot);
  }

  void SetTreeDBuf(const char* tree_d_cache, const char* file_prefix,
                   bool include_slot = false) {
    SetTreeBufs(&tree_d_buf_, tree_d_cache,
                file_prefix, 1, include_slot);
    if (tree_d_buf_.is_open() == 0) {
      printf("No tree d file, assuming CC sector\n");
      // TODO: for 64GB would need to access the next layer. CC_TREE_D_NODE_VALUES
      // would need to be filled in.
      assert (C::GetNumTreeDLevels() <= 31);
      comm_d_ = (node_t*) CC_TREE_D_NODE_VALUES[C::GetNumTreeDLevels()];
    } else {
      uint8_t* comm_d_addr = (uint8_t*)&tree_d_buf_[0] +
                              (tree_d_buf_.get_size() - sizeof(node_t));
      comm_d_ = (node_t*)comm_d_addr;
    }
  }

  void GetRoots(const char* cache);
  void SetParentsBuf(const char* filename);
  void SetReplicaBuf(const char* cache);

  void WriteProofs(const char* filename, bool do_tree, bool do_node);

  size_t ProofSize(bool do_tree, bool do_node);

  void CombineProofs(const char* filename,
                     const char* tree_filename,
                     const char* node_filename);
 private:
  void WriteTreeDProof(uint64_t challenge);
  void SetTreeBufs(mmap_t<node_t>* bufs, const char* cache,
                   const char* prefix, size_t num_files, bool include_slot);

  streaming_node_reader_t<C>& reader_;
  size_t                      sector_slot_;
  const node_t*               replica_id_;
  uint64_t*                   challenges_;
  size_t                      challenges_count_;
  mmap_t<node_t>              replica_buf_;
  std::vector<mmap_t<node_t>> tree_r_bufs_;
  std::vector<mmap_t<node_t>> tree_c_bufs_;
  mmap_t<node_t>              tree_d_buf_;
  node_t                      tree_c_root_;
  node_t                      tree_r_root_;
  node_t                      comm_r_;
  node_t*                     comm_d_;
  const node_t*               seed_;
  const node_t*               ticket_;
  mmap_t<uint32_t>            parents_buf_;
};

template<class C>
C1<C>::C1(streaming_node_reader_t<C>& reader, size_t sector_slot) :
  reader_(reader), sector_slot_(sector_slot) {

  challenges_count_ = C::GetNumChallenges() / C::GetNumPartitions();

  challenges_  = nullptr;
}

template<class C>
C1<C>::~C1() {
  if (challenges_  != nullptr) delete challenges_;
}

// https://spec.filecoin.io/#section-algorithms.sdr.porep-challenges
template<class C>
void C1<C>::DeriveChallenges(const uint8_t* seed) {
  seed_   = (node_t*) seed;

  uint32_t hash[8] __attribute__ ((aligned (32)));
  size_t leaves = C::GetNumLeaves();
  challenges_   = new uint64_t[C::GetNumChallenges()];

  for (uint8_t k = 0; k < C::GetNumPartitions(); ++k) {
    uint8_t buf[128] __attribute__ ((aligned (32))) = {0};
    std::memcpy(buf, replica_id_, 32);
    std::memcpy(buf + 32, seed, 32);
    buf[68] = 0x80;  // padding
    // 544 bits -> 0x220
    buf[126] = 0x02; // padding length
    buf[127] = 0x20; // padding length

    mpz_t gmp_challenge;
    mpz_init(gmp_challenge);

    for (size_t i = 0; i < challenges_count_; ++i) {
      uint32_t j = (uint32_t)((challenges_count_ * k) + i);
      buf[64] = (uint8_t)(j & 0xFF);
      buf[65] = (uint8_t)((j >> 8) & 0xFF);

      std::memcpy(hash, SHA256_INITIAL_DIGEST, NODE_SIZE);
      blst_sha256_block(hash, buf, 2);
      blst_sha256_emit((uint8_t*)hash, hash);

      mpz_import(gmp_challenge, 8, -1, 4, 0, 0, hash);

      // Resulting challenge must be a leaf index and not the first leaf
      // Use gmp to perform modulo operation
      challenges_[i + (k * challenges_count_)] =
        mpz_mod_ui(gmp_challenge, gmp_challenge, leaves - 1) + 1;
    }
    mpz_clear(gmp_challenge);

  }
}

template<class C>
void C1<C>::SetParentsBuf(const char* filename) {
  assert (parents_buf_.mmap_read(filename) == 0);
}

template<class C>
void C1<C>::SetReplicaBuf(const char* cache) {
  const char* rep_template = "%s/sealed-file";;
  const size_t MAX = 256;
  char fname[MAX];
  snprintf(fname, MAX, rep_template, cache);
  assert (replica_buf_.mmap_read(fname) == 0);
}

template<class C>
void C1<C>::SetTreeBufs(mmap_t<node_t>* bufs, const char* cache,
                        const char* prefix, size_t num_files,
                        bool include_slot) {
  for (size_t l = 0; l < num_files; ++l) {
    const size_t MAX = 256;
    char fname[MAX];
    if (include_slot) {
      snprintf(fname, MAX, prefix, cache, sector_slot_, l);
    } else {
      if (num_files == 1) {
        snprintf(fname, MAX, prefix, cache);
      } else {
        snprintf(fname, MAX, prefix, cache, l);
      }
    }

    int tree_fd = open(fname, O_RDONLY);
    if (tree_fd == -1) {
      printf("Failed to open tree file %s\n", fname);
      break;
    }
    close(tree_fd);

    assert (bufs[l].mmap_read(fname) == 0);
  }
}

template<class C>
void C1<C>::GetRoots(const char* cache) {
  // Get tree_c_root and tree_r_last_root from p_aux file
  const char* p_aux_template = "%s/p_aux";
  const size_t MAX = 256;
  char fname[MAX];
  snprintf(fname, MAX, p_aux_template, cache);

  mmap_t<node_t> p_aux_buf;
  p_aux_buf.mmap_read(fname);

  std::memcpy(&tree_c_root_, &(p_aux_buf[0]), sizeof(node_t));
  std::memcpy(&tree_r_root_, &(p_aux_buf[1]), sizeof(node_t));

  // Calculate comm r
  Poseidon poseidon_comm_r(2);
  poseidon_comm_r.Hash((uint8_t*)&comm_r_, (uint8_t*)&p_aux_buf[0]);
}

template<class C>
size_t C1<C>::ProofSize(bool do_tree, bool do_node) {
  uint64_t num_partitions = C::GetNumPartitions();
  uint64_t num_challenges = C::GetNumChallenges();

  size_t tree_d_proof_size =  TreeProof::ProofSize(C::GetNumTreeDArity(),
    C::GetNumTreeDLevels(), SINGLE_PROOF_DATA);
  size_t tree_rc_proof_size = TreeProof::ProofSize(C::GetNumTreeRCArity(),
    C::GetNumTreeRCLevels(), C::GetNumTreeRCConfig());
  size_t tree_proof_size = tree_d_proof_size + tree_rc_proof_size;

  size_t label_proof_size =  LabelProof::ProofSize(C::GetNumLayers(),
                                                   false);
  size_t enc_proof_size =  LabelProof::ProofSize(C::GetNumLayers(),
                                                 true);
  size_t col_proof_size = ((1 + PARENT_COUNT_BASE + PARENT_COUNT_EXP) *
                           ColumnProof<C>::ProofSize()) +
                           (2 * sizeof(uint64_t));

  size_t node_proof_size = label_proof_size + enc_proof_size + col_proof_size;

  size_t proof_size = (num_partitions * sizeof(uint64_t)) + sizeof(uint64_t);

  if (do_tree == true) {
    proof_size += (tree_proof_size * num_challenges);
    proof_size += 2 * sizeof(node_t);
  }

  if (do_node == true) {
    proof_size += (node_proof_size * num_challenges);
    proof_size += 3 * sizeof(node_t);
  }

  return proof_size;
}

template<class C>
void C1<C>::WriteProofs(const char* filename, bool do_tree, bool do_node) {
  remove(filename);
  mmap_t<uint8_t> file_ptr;
  size_t expected_file_size = ProofSize(do_tree, do_node);
  file_ptr.mmap_write(filename, expected_file_size);

  size_t buf_index = 0;

  // Need to put together  pub vanilla_proofs: Vec<Vec<VanillaSealProof<Tree>>>,
  uint64_t vp_outer_length = C::GetNumPartitions();
  uint64_t vp_inner_length = challenges_count_;

  std::memcpy(&file_ptr[0] + buf_index, &vp_outer_length, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);

  // Gather the output buffers into a contiguous array to keep challenge agnostic
  // about file IO
  size_t num_files = C::GetNumTreeRCFiles();
  std::vector<node_t*> tree_r(num_files);
  std::vector<node_t*> tree_c(num_files);
  for (size_t i = 0; i < num_files; i++) {
    tree_r[i] = &tree_r_bufs_[i][0];
    tree_c[i] = &tree_c_bufs_[i][0];
  }
  node_t* tree_d = tree_d_buf_.is_open() ? &tree_d_buf_[0] : nullptr;

  for (uint64_t i = 0; i < vp_outer_length; ++i) {
    std::memcpy(&file_ptr[0] + buf_index, &vp_inner_length, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    for (uint64_t j = 0; j < vp_inner_length; ++j) {
      C1Challenge<C> challenge(challenges_[j + (i * challenges_count_)],
                                  &tree_r_root_, &tree_c_root_, comm_d_);


      if (do_node == true) {
        challenge.GetParents(&parents_buf_[0]);
        challenge.GetNodes(reader_, sector_slot_);
        if (do_tree == true) {
          challenge.GetTreeRNodes(replica_buf_);
          buf_index = challenge.WriteProof(&file_ptr[0], buf_index, &tree_r[0],
                                           &tree_c[0], tree_d);
        } else {
          buf_index = challenge.WriteNodeProof(&file_ptr[0], buf_index,
                                               &tree_c[0]);
        }
      } else {
        challenge.GetTreeRNodes(replica_buf_);
        buf_index = challenge.WriteTreeProof(&file_ptr[0], buf_index,
                                             &tree_r[0], tree_d);
      }
    }
  }

  if (do_tree == true) {
    // Comm R
    std::memcpy(&file_ptr[0] + buf_index, &comm_r_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Comm D
    std::memcpy(&file_ptr[0] + buf_index, comm_d_, sizeof(node_t));
    buf_index += sizeof(node_t);
  }

  if (do_node == true) {
    // Replica ID
    std::memcpy(&file_ptr[0] + buf_index, replica_id_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Seed
    std::memcpy(&file_ptr[0] + buf_index, seed_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Ticket
    std::memcpy(&file_ptr[0] + buf_index, ticket_, sizeof(node_t));
    buf_index += sizeof(node_t);
  }

  //printf("WriteProofs buf_index %ld\n", buf_index);
  assert(buf_index == expected_file_size);
}

template<class C>
void C1<C>::CombineProofs(const char* filename,
                             const char* tree_filename,
                             const char* node_filename) {
  remove(filename);
  mmap_t<uint8_t> file_ptr;
  size_t expected_file_size = ProofSize(true, true);
  file_ptr.mmap_write(filename, expected_file_size);

  mmap_t<uint8_t> tree_ptr;
  size_t exp_tree_buf_size = ProofSize(true, false);
  tree_ptr.mmap_write(tree_filename, exp_tree_buf_size);

  mmap_t<uint8_t> node_ptr;
  node_ptr.mmap_read(node_filename);

  size_t buf_index = 0;
  size_t tree_buf_index = 0;
  size_t node_buf_index = 0;

  size_t tree_d_proof_size =  TreeProof::ProofSize(C::GetNumTreeDArity(),
    C::GetNumTreeDLevels(), SINGLE_PROOF_DATA);
  size_t tree_rc_proof_size = TreeProof::ProofSize(C::GetNumTreeRCArity(),
    C::GetNumTreeRCLevels(), C::GetNumTreeRCConfig());
  size_t tree_proof_size = tree_d_proof_size + tree_rc_proof_size;

  size_t label_proof_size =  LabelProof::ProofSize(C::GetNumLayers(),
                                                   false);
  size_t enc_proof_size =  LabelProof::ProofSize(C::GetNumLayers(),
                                                 true);
  size_t col_proof_size = ((1 + PARENT_COUNT_BASE + PARENT_COUNT_EXP) *
                           ColumnProof<C>::ProofSize()) +
                           (2 * sizeof(uint64_t));
  size_t node_proof_size = label_proof_size + enc_proof_size + col_proof_size;

  // Need to put together  pub vanilla_proofs: Vec<Vec<VanillaSealProof<Tree>>>,
  uint64_t vp_outer_length = C::GetNumPartitions();
  uint64_t vp_inner_length = challenges_count_;

  std::memcpy(&file_ptr[0] + buf_index, &vp_outer_length, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);
  tree_buf_index += sizeof(uint64_t);
  node_buf_index += sizeof(uint64_t);

  for (uint64_t i = 0; i < vp_outer_length; ++i) {
    std::memcpy(&file_ptr[0] + buf_index, &vp_inner_length, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);
    tree_buf_index += sizeof(uint64_t);
    node_buf_index += sizeof(uint64_t);

    for (uint64_t j = 0; j < vp_inner_length; ++j) {
      std::memcpy(&file_ptr[0] + buf_index, &tree_ptr[0] + tree_buf_index, tree_proof_size);
      buf_index += tree_proof_size;
      tree_buf_index += tree_proof_size;

      std::memcpy(&file_ptr[0] + buf_index, &node_ptr[0] + node_buf_index, node_proof_size);
      buf_index += node_proof_size;
      node_buf_index += node_proof_size;
    }
  }

  // Comm R
  std::memcpy(&file_ptr[0] + buf_index, &tree_ptr[0] + tree_buf_index, sizeof(node_t));
  buf_index += sizeof(node_t);
  tree_buf_index += sizeof(node_t);

  // Comm D
  std::memcpy(&file_ptr[0] + buf_index, &tree_ptr[0] + tree_buf_index, sizeof(node_t));
  buf_index += sizeof(node_t);
  tree_buf_index += sizeof(node_t);

  // Replica ID
  std::memcpy(&file_ptr[0] + buf_index, &node_ptr[0] + node_buf_index, sizeof(node_t));
  buf_index += sizeof(node_t);
  node_buf_index += sizeof(node_t);

  // Seed
  std::memcpy(&file_ptr[0] + buf_index, &node_ptr[0] + node_buf_index, sizeof(node_t));
  buf_index += sizeof(node_t);
  node_buf_index += sizeof(node_t);

  // Ticket
  std::memcpy(&file_ptr[0] + buf_index, &node_ptr[0] + node_buf_index, sizeof(node_t));
  buf_index += sizeof(node_t);
  node_buf_index += sizeof(node_t);

  assert(buf_index == expected_file_size);
  assert(tree_buf_index == exp_tree_buf_size);
  assert(node_buf_index == node_ptr.get_size());
}


template<class C>
int do_c1(streaming_node_reader_t<C>& reader,
          size_t num_sectors, size_t sector_slot,
          const uint8_t* replica_id, const uint8_t* seed,
          const uint8_t* ticket, const char* cache_path,
          const char* parents_filename, const char* replica_path,
          const char* output_dir) {
  C1<C> c1(reader, sector_slot);
  c1.SetReplicaID((node_t*)replica_id);
  c1.SetTicket((node_t*)ticket);

  c1.DeriveChallenges(seed);
  if (C::GetNumTreeRCFiles() == 1) {
    c1.SetTreeRBufs(cache_path, "%s/sc-02-data-tree-r-last.dat");
    c1.SetTreeCBufs(cache_path, "%s/sc-02-data-tree-c.dat");
  } else {
    c1.SetTreeRBufs(cache_path, "%s/sc-02-data-tree-r-last-%ld.dat");
    c1.SetTreeCBufs(cache_path, "%s/sc-02-data-tree-c-%ld.dat");
  }
  c1.SetTreeDBuf(cache_path, "%s/sc-02-data-tree-d.dat");

  c1.GetRoots(cache_path);
  c1.SetReplicaBuf(replica_path);
  c1.SetParentsBuf(parents_filename);

  const size_t MAX = 256;
  char fname[MAX];
  snprintf(fname, MAX, "%s/commit-phase1-output", output_dir);
  c1.WriteProofs(fname, true, true);

  return 0;
}

template<class C>
int do_c1_tree(streaming_node_reader_t<C>& reader,
               size_t num_sectors, size_t sector_slot,
               const uint8_t* replica_id, const uint8_t* seed,
               const uint8_t* ticket, const char* cache_path,
               const char* parents_filename, const char* replica_path,
               const char* output_dir) {
  C1<C> c1_tree(reader, sector_slot);
  c1_tree.SetReplicaID((node_t*)replica_id);
  c1_tree.DeriveChallenges(seed);
  if (C::GetNumTreeRCFiles() == 1) {
    c1_tree.SetTreeRBufs(cache_path, "%s/sc-02-data-tree-r-last.dat");
  } else {
    c1_tree.SetTreeRBufs(cache_path, "%s/sc-02-data-tree-r-last-%ld.dat");
  }
  c1_tree.SetTreeDBuf(cache_path, "%s/sc-02-data-tree-d.dat");
  c1_tree.GetRoots(cache_path);
  c1_tree.SetReplicaBuf(replica_path);

  const size_t MAX = 256;
  char fname_tree[MAX];
  snprintf(fname_tree, MAX, "%s/commit-phase1-output-tree", output_dir);
  c1_tree.WriteProofs(fname_tree, true, false);

  return 0;
}

template<class C>
int do_c1_node(streaming_node_reader_t<C>& reader,
               size_t num_sectors, size_t sector_slot,
               const uint8_t* replica_id, const uint8_t* seed,
               const uint8_t* ticket, const char* cache_path,
               const char* parents_filename, const char* replica_path,
               const char* output_dir) {
  C1<C> c1_node(reader, sector_slot);
  c1_node.SetReplicaID((node_t*)replica_id);
  c1_node.SetTicket((node_t*)ticket);
  c1_node.DeriveChallenges(seed);
  if (C::GetNumTreeRCFiles() == 1) {
    c1_node.SetTreeCBufs(cache_path, "%s/sc-02-data-tree-c.dat");
  } else {
    c1_node.SetTreeCBufs(cache_path, "%s/sc-02-data-tree-c-%ld.dat");
  }
  c1_node.SetParentsBuf(parents_filename);
  c1_node.GetRoots(cache_path);

  const size_t MAX = 256;
  char fname_node[MAX];
  snprintf(fname_node, MAX, "%s/commit-phase1-output-node", output_dir);
  c1_node.WriteProofs(fname_node, false, true);

  return 0;
}

template<class C>
int do_c1_comb(streaming_node_reader_t<C>& reader,
               size_t num_sectors, size_t sector_slot,
               const uint8_t* replica_id, const uint8_t* seed,
               const uint8_t* ticket, const char* cache_path,
               const char* parents_filename, const char* replica_path,
               const char* output_dir) {
  C1<C> c1_combine(reader, sector_slot);

  const size_t MAX = 256;
  char fname_tree[MAX];
  snprintf(fname_tree, MAX, "%s/commit-phase1-output-tree", output_dir);

  char fname_node[MAX];
  snprintf(fname_node, MAX, "%s/commit-phase1-output-node", output_dir);

  char fname_comb[MAX];
  snprintf(fname_comb, MAX, "%s/commit-phase1-output-comb", output_dir);

  c1_combine.CombineProofs(fname_comb, fname_tree, fname_node);

  return 0;
}
// Copyright Supranational LLC

#ifndef __C1CHALLENGE_HPP__
#define __C1CHALLENGE_HPP__

template<class C>
class C1Challenge {
 public:
  C1Challenge(uint64_t challenge,
              node_t* tree_r_root_, node_t* tree_c_root_, node_t* tree_d_root);
  ~C1Challenge();

  void GetParents(const uint32_t* parents_buf);
  void GetNodes(streaming_node_reader_t<C>& reader, size_t sector_slot);
  void GetTreeRNodes(node_t* replica_buf);
  size_t WriteTreeProof(uint8_t* file_ptr, size_t buf_index,
                        node_t** tree_r_bufs, node_t* tree_d_buf);
  size_t WriteNodeProof(uint8_t* file_ptr, size_t buf_index,
                        node_t** tree_c_bufs);
  size_t WriteProof(uint8_t* file_ptr, size_t buf_index,
                    node_t** tree_r_bufs, node_t** tree_c_bufs,
                    node_t* tree_d_buf);

 private:
  uint64_t          challenge_;
  uint32_t          drg_parents_[PARENT_COUNT_BASE];
  uint32_t          exp_parents_[PARENT_COUNT_EXP];
  node_t*           nodes_;        // This node and its parents for each layer
  node_t*           tree_r_nodes_; // Replica nodes to rebuild discarded rows
  node_t*           tree_r_root_;
  node_t*           tree_c_root_;
  node_t*           tree_d_root_;
};

template<class C>
C1Challenge<C>::C1Challenge(uint64_t challenge,
                            node_t* tree_r_root, node_t* tree_c_root,
                            node_t* tree_d_root) :
  challenge_(challenge),
  tree_r_root_(tree_r_root),
  tree_c_root_(tree_c_root),
  tree_d_root_(tree_d_root) {

  nodes_        = new node_t[C::GetNumLayers() * (PARENT_COUNT + 1)];
  tree_r_nodes_ = new node_t[C::GetNumTreeRLabels()];
}

template<class C>
C1Challenge<C>::~C1Challenge() {
  if (nodes_        != nullptr) delete nodes_;
  if (tree_r_nodes_ != nullptr) delete tree_r_nodes_;
}

template<class C>
void C1Challenge<C>::GetParents(const uint32_t* parents_buf) {
  size_t p_idx = challenge_ * PARENT_COUNT;
  for (size_t k = 0; k < PARENT_COUNT_BASE; ++k) {
    drg_parents_[k] = parents_buf[p_idx];
    p_idx++;
  }
  for (size_t k = 0; k < PARENT_COUNT_EXP; ++k) {
    exp_parents_[k] = parents_buf[p_idx];
    p_idx++;
  }
}

template<class C>
void C1Challenge<C>::GetNodes(streaming_node_reader_t<C>& reader,
                              size_t sector_slot) {
  std::vector<std::pair<size_t, size_t>> nodes;

  size_t layer_count = C::GetNumLayers();
  for (size_t l = 0; l < layer_count; ++l) {
    nodes.push_back(std::pair(l, challenge_));

    // Get all base parents
    for (size_t k = 0; k < PARENT_COUNT_BASE; ++k) {
      nodes.push_back(std::pair(l, drg_parents_[k]));
    }

    // Get all exp parents
    for (size_t k = 0; k < PARENT_COUNT_EXP; ++k) {
      nodes.push_back(std::pair(l, exp_parents_[k]));
    }
  }
  reader.alloc_slots(1, nodes.size(), false);
  reader.load_nodes(0, nodes);
  for (size_t i = 0; i < nodes.size(); i++) {
    node_t n = reader.get_node(0, nodes, i, sector_slot);
    nodes_[i] = n;
  }
  reader.free_slots();
}

template<class C>
void C1Challenge<C>::GetTreeRNodes(node_t* replica_buf) {
  size_t tree_r_label_idx  = challenge_ & C::GetChallengeStartMask();
  for (size_t k = 0; k < C::GetNumTreeRLabels(); ++k) {
    std::memcpy(tree_r_nodes_ + k, &(replica_buf[tree_r_label_idx]),
                sizeof(node_t));
    tree_r_label_idx++;
  }
}

template<class C>
size_t C1Challenge<C>::WriteTreeProof(uint8_t* file_ptr, size_t buf_index,
                                      node_t** tree_r_bufs, node_t* tree_d_buf) {
  ///////////////////////////////////////
  // Build Tree D inclusion proof
  ///////////////////////////////////////
  if (tree_d_buf == nullptr) {
    TreeDCCProof tree_d(C::GetNumTreeDArity(),
                        C::GetNumTreeDLevels(), nullptr, 0, 0);
    tree_d.GenInclusionPath(challenge_, (node_t*) CC_TREE_D_NODE_VALUES);
    buf_index = tree_d.WriteProof(file_ptr, buf_index, SINGLE_PROOF_DATA);
  } else {
    TreeProof tree_d(C::GetNumTreeDArity(),
                     C::GetNumTreeDLevels(), &tree_d_buf, 1, 0);
    tree_d.SetRoot(tree_d_root_);
    tree_d.GenInclusionPath(challenge_, nullptr);
    buf_index = tree_d.WriteProof(file_ptr, buf_index, SINGLE_PROOF_DATA);
  }

  ///////////////////////////////////////
  // Build Tree R inclusion proof
  ///////////////////////////////////////
  TreeProof tree_r(C::GetNumTreeRCArity(),
                   C::GetNumTreeRCLevels(), tree_r_bufs,
                   C::GetNumTreeRCFiles(),
                   C::GetNumTreeRDiscardRows());
  tree_r.SetRoot(tree_r_root_);
  tree_r.GenInclusionPath(challenge_, tree_r_nodes_);
  buf_index = tree_r.WriteProof(file_ptr, buf_index,
                                C::GetNumTreeRCConfig());

  return buf_index;
}

template<class C>
size_t C1Challenge<C>::WriteNodeProof(uint8_t* file_ptr, size_t buf_index,
                                      node_t** tree_c_bufs) {
  ///////////////////////////////////////
  // Column proofs
  ///////////////////////////////////////
  ColumnProof c_x = ColumnProof<C>(challenge_,
                                   nodes_, 0, (PARENT_COUNT + 1),
                                   tree_c_bufs, tree_c_root_);
  buf_index = c_x.WriteProof(file_ptr, buf_index,
                             C::GetNumTreeRCConfig());

  ///////////////////////////////////////
  // DRG Parents
  ///////////////////////////////////////
  std::memcpy(file_ptr + buf_index, &PARENT_COUNT_BASE, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);

  for (size_t k = 0; k < PARENT_COUNT_BASE; ++k) {
    ColumnProof drg = ColumnProof<C>(drg_parents_[k],
                                     nodes_, k + 1, (PARENT_COUNT + 1),
                                     tree_c_bufs, tree_c_root_);
    buf_index = drg.WriteProof(file_ptr, buf_index,
                               C::GetNumTreeRCConfig());
  }

  ///////////////////////////////////////
  // Expander Parents
  ///////////////////////////////////////
  std::memcpy(file_ptr + buf_index, &PARENT_COUNT_EXP, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);

  for (size_t k = 0; k < PARENT_COUNT_EXP; ++k) {
    ColumnProof exp = ColumnProof<C>(exp_parents_[k], nodes_,
                                     k + 1 + PARENT_COUNT_BASE,
                                     (PARENT_COUNT + 1),
                                     tree_c_bufs, tree_c_root_);
    buf_index = exp.WriteProof(file_ptr, buf_index,
                               C::GetNumTreeRCConfig());
  }

  ///////////////////////////////////////
  // Labeling Proofs
  ///////////////////////////////////////
  size_t layer_count = C::GetNumLayers();
  LabelProof label_proof(challenge_, layer_count, nodes_, (PARENT_COUNT + 1));
  buf_index = label_proof.WriteProof(file_ptr, buf_index);

  ///////////////////////////////////////
  // Encoding Proof
  ///////////////////////////////////////
  LabelProof enc_proof(challenge_, layer_count, nodes_, (PARENT_COUNT + 1));
  buf_index = enc_proof.WriteProof(file_ptr, buf_index, true);

  return buf_index;
}

template<class C>
size_t C1Challenge<C>::WriteProof(uint8_t* file_ptr, size_t buf_index,
                                  node_t** tree_r_bufs, node_t** tree_c_bufs,
                                  node_t* tree_d_buf) {
  buf_index = WriteTreeProof(file_ptr, buf_index, tree_r_bufs, tree_d_buf);
  buf_index = WriteNodeProof(file_ptr, buf_index, tree_c_bufs);

  return buf_index;
}
#endif // __C1CHALLENGE_HPP__
// Copyright Supranational LLC

#ifndef __LABEL_PROOF_HPP__
#define __LABEL_PROOF_HPP__

#include "../sealing/data_structures.hpp"

class LabelProof {
 public:
  LabelProof(uint64_t challenge, uint64_t layers,
             node_t* labels, size_t label_inc);
  ~LabelProof() { }

  size_t WriteProof(uint8_t* file_ptr, size_t buf_index, bool enc = false);
  static size_t ProofSize(size_t layers, bool enc);

 private:
  uint64_t   challenge_;
  uint64_t   layers_;
  node_t*  labels_;
  size_t     label_inc_;
};

LabelProof::LabelProof(uint64_t challenge, uint64_t layers,
                       node_t* labels, size_t label_inc) :
  challenge_(challenge),
  layers_(layers),
  labels_(labels),
  label_inc_(label_inc) { }

size_t LabelProof::ProofSize(size_t layers, bool enc) {
  size_t proof_size = 8;

  if ((enc == false) || (layers == 1)) {
    if (enc == false)
      proof_size += (layers * 8);
    proof_size += sizeof(node_t) * LAYER_ONE_REPEAT_SEQ * PARENT_COUNT_BASE;
    proof_size += sizeof(node_t) * LAYER_ONE_FINAL_SEQ;
    proof_size += 4;
    proof_size += 8;
    layers--;
  }

  if ((enc == true) && (layers > 1)) {
    layers = 1;
  }

  proof_size += (layers * sizeof(node_t) * LAYER_N_REPEAT_SEQ *
                 PARENT_COUNT_BASE);
  proof_size += (layers * sizeof(node_t) * LAYER_N_REPEAT_SEQ *
                 PARENT_COUNT_EXP);
  proof_size += (layers * sizeof(node_t) * LAYER_N_FINAL_SEQ);
  proof_size += (layers * 4);
  proof_size += (layers * 8);

  return proof_size;
}

size_t LabelProof::WriteProof(uint8_t* file_ptr, size_t buf_index,
                              bool enc) {
  uint32_t l = 1;

  if (enc == true) { // Encoding, only last layer
    l = layers_;
  } else {
    // Write vector length of proofs
    std::memcpy(file_ptr + buf_index, &layers_, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);
  }

  while (l <= layers_) {
    // Number of parents in label calculation
    std::memcpy(file_ptr + buf_index, &LABEL_PARENTS, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    if (l == 1) {
      for (size_t k = 0; k < LAYER_ONE_REPEAT_SEQ; ++k) {
        for (size_t c = 0; c < PARENT_COUNT_BASE; ++c) {
          std::memcpy(file_ptr + buf_index,
            labels_ + c + 1 + ((l - 1) * label_inc_), sizeof(node_t));
          buf_index += sizeof(node_t);
        }
      }

      for (size_t c = 0; c < LAYER_ONE_FINAL_SEQ; ++c) {
        std::memcpy(file_ptr + buf_index,
                    labels_ + c + 1 + ((l - 1) * label_inc_), sizeof(node_t));
        buf_index += sizeof(node_t);
      }
    } else {
      for (size_t k = 0; k < LAYER_N_REPEAT_SEQ; ++k) {
        for (size_t c = 0; c < PARENT_COUNT_BASE; ++c) {
          std::memcpy(file_ptr + buf_index,
            labels_ + c + 1 + ((l - 1) * label_inc_), sizeof(node_t));
          buf_index += sizeof(node_t);
        }

        for (size_t c = 0; c < PARENT_COUNT_EXP; ++c) {
          std::memcpy(file_ptr + buf_index,
            labels_ + c + 1 + PARENT_COUNT_BASE + ((l - 2) * label_inc_),
            sizeof(node_t));
          buf_index += sizeof(node_t);
        }
      }

      for (size_t c = 0; c < LAYER_N_FINAL_SEQ; ++c) {
        if (c < PARENT_COUNT_BASE) {
          std::memcpy(file_ptr + buf_index,
            labels_ + c + 1 + ((l - 1) * label_inc_), sizeof(node_t));
        } else {
          std::memcpy(file_ptr + buf_index,
            labels_ + c + 1 + ((l - 2) * label_inc_),
            sizeof(node_t));
        }
        buf_index += sizeof(node_t);
      }
    }

    // Layer index
    std::memcpy(file_ptr + buf_index, &l, sizeof(uint32_t));
    buf_index += sizeof(uint32_t);

    // Node - challenge
    std::memcpy(file_ptr + buf_index, &challenge_, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    l++;
  }

  return buf_index;
}

#endif // __LABEL_PROOF_HPP__
// Copyright Supranational LLC

#ifndef __PATH_ELEMENT_HPP__
#define __PATH_ELEMENT_HPP__

class PathElement {
 public:
  PathElement(size_t arity, uint64_t index);
  ~PathElement();
  void SetHash(size_t index, node_t* hash) { hashes_[index] = hash; }
  size_t Write(uint8_t* file_ptr, size_t buf_index);

 private:
  size_t     arity_;
  uint64_t   index_;
  node_t** hashes_; // arity - 1 hashes
};

PathElement::PathElement(size_t arity, uint64_t index) :
  arity_(arity),
  index_(index) {
  hashes_ = new node_t*[arity - 1]{ nullptr };
}

PathElement::~PathElement() {
  delete hashes_;
}

size_t PathElement::Write(uint8_t* file_ptr, size_t buf_index) {
  uint64_t len = (uint64_t)arity_ - 1;
  std::memcpy(file_ptr + buf_index, &len, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);

  for(uint64_t i = 0; i < len; ++i) {
    std::memcpy(file_ptr + buf_index, hashes_[i], sizeof(node_t));
    buf_index += sizeof(node_t);
  }

  std::memcpy(file_ptr + buf_index, &index_, sizeof(uint64_t));
  buf_index += sizeof(uint64_t);

  return buf_index;
}
#endif // __PATH_ELEMENT_HPP__
// Copyright Supranational LLC

#ifndef __STREAMING_LAYER_READER_FILES_HPP__
#define __STREAMING_LAYER_READER_FILES_HPP__

#include <vector>
#include <string>
#include <string.h>
#include "../util/mmap_t.hpp"
#include <util/thread_pool_t.hpp>

// Encapsulate the SPDK portion of reading layers from files
// C is not used here but is retained to be consistent with
// multi-sector c1
template<class C>
class streaming_node_reader_t {
  std::vector<mmap_t<node_t>> layer_files;
  // Packed indicates nodes within a single layer will be contiguous
  bool packed;
  size_t num_slots;
  size_t pages_per_slot;

  node_t* buffer;

  thread_pool_t pool;

public:
  streaming_node_reader_t(size_t sector_size, std::vector<std::string> layer_filenames)
    : buffer(nullptr)
  {
    layer_files.resize(layer_filenames.size());
    for (size_t i = 0; i < layer_filenames.size(); i++) {
      layer_files[i].mmap_read(layer_filenames[i], sector_size);
    }
  }

  ~streaming_node_reader_t() {
    free_slots();
  }

  bool data_is_big_endian() {
    return true;
  }

  // Allocate resource to perform N reads, each of size slot_node_count. These
  // will be indexed by slot_id
  // For C1 (load_nodes, get_node), we don't need local storage because it can
  // just use the mmapped files.
  // For PC2 create buffers to consolidate the data.
  void alloc_slots(size_t _num_slots, size_t slot_node_count, bool _packed) {
    packed = _packed;
    if (!packed) {
      // Reading will occur directly from files, so do nothing
    } else {
      pages_per_slot = (slot_node_count + C::NODES_PER_PAGE - 1) / C::NODES_PER_PAGE;
      num_slots = _num_slots;
      assert (posix_memalign((void **)&buffer, PAGE_SIZE,
                             num_slots * pages_per_slot * PAGE_SIZE) == 0);
    }
  }

  node_t* get_full_buffer(size_t &bytes) {
    bytes = num_slots * pages_per_slot * PAGE_SIZE;
    return buffer;
  }

  node_t* get_slot(size_t slot) {
    return &buffer[slot * pages_per_slot * C::NODES_PER_PAGE];
  }

  void free_slots() {
    free(buffer);
    buffer = nullptr;
  }

  ////////////////////////////////////////
  // Used for PC2
  ////////////////////////////////////////
  node_t* load_layers(size_t slot, uint32_t layer, uint64_t node,
                      size_t node_count, size_t num_layers,
                      std::atomic<uint64_t>* valid, size_t* valid_count) {
    if (num_layers == 1) {
      // Simply return a pointer to the mmap'd file data
      // This is used by pc2 when bulding just tree-r
      assert (layer == C::GetNumLayers() - 1);
      assert (C::PARALLEL_SECTORS == 1);
      assert (layer_files.size() == 1);

      *valid = 1;
      *valid_count = 1;

      return &layer_files[0][node];
    } else {
      // Consolidate the layer data into the buffer
      assert (C::PARALLEL_SECTORS == 1);
      assert (layer_files.size() == num_layers);
      // Nodes in each layer are expected to evenly fit in a page so that
      // the result is packed
      assert (node_count % C::NODES_PER_PAGE == 0);
      node_t* dest = &buffer[slot * pages_per_slot * C::NODES_PER_PAGE];

      pool.par_map(num_layers, 1, [&](size_t i) {
        layer_files[i].read_data(node, &dest[i * node_count], node_count);
      });

      *valid = 1;
      *valid_count = 1;

      return dest;
    }
  }

  ////////////////////////////////////////
  // Used for C1
  ////////////////////////////////////////

  // Load a vector of node IDs into the local buffer
  // The nodes are a vector of layer, node_id pairs
  // Since the nodes may be non-consecutive each node will use
  // an entire page in the buffer.
  int load_nodes(size_t slot, std::vector<std::pair<size_t, size_t>>& nodes) {
    assert (!packed);
    return 0;
  }

  // Retrieve a sector and node from the local buffer
  //   nodes       - the vector of nodes originally read into the local buffer
  //   idx         - the index of the node to retrieve
  //   sector_slot - the slot to retrive
  node_t& get_node(size_t slot, std::vector<std::pair<size_t, size_t>>& nodes,
                   size_t idx, size_t sector_slot) {
    assert (!packed);
    size_t layer = nodes[idx].first;
    size_t node = nodes[idx].second;
    node_t& n = layer_files[layer][node];
    return n;
  }
};

#endif
const uint8_t CC_TREE_D_NODE_VALUES[][32] = {
  { 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 },
  { 0xf5, 0xa5, 0xfd, 0x42, 0xd1, 0x6a, 0x20, 0x30,
    0x27, 0x98, 0xef, 0x6e, 0xd3, 0x09, 0x97, 0x9b,
    0x43, 0x00, 0x3d, 0x23, 0x20, 0xd9, 0xf0, 0xe8,
    0xea, 0x98, 0x31, 0xa9, 0x27, 0x59, 0xfb, 0x0b },
  { 0x37, 0x31, 0xbb, 0x99, 0xac, 0x68, 0x9f, 0x66,
    0xee, 0xf5, 0x97, 0x3e, 0x4a, 0x94, 0xda, 0x18,
    0x8f, 0x4d, 0xdc, 0xae, 0x58, 0x07, 0x24, 0xfc,
    0x6f, 0x3f, 0xd6, 0x0d, 0xfd, 0x48, 0x83, 0x33 },
  { 0x64, 0x2a, 0x60, 0x7e, 0xf8, 0x86, 0xb0, 0x04,
    0xbf, 0x2c, 0x19, 0x78, 0x46, 0x3a, 0xe1, 0xd4,
....

// Copyright Supranational LLC

#ifndef __TREE_PROOF_HPP__
#define __TREE_PROOF_HPP__

#include "tree_d_cc_nodes.h"

class TreeProof {
 public:
  TreeProof(size_t arity, size_t levels,
            node_t** tree_bufs, size_t num_tree_bufs,
            size_t discard_rows);
  virtual ~TreeProof();

  void   SetRoot(node_t* root) { root_ = root; }
  void   SetLeaf(node_t* leaf) { leaf_ = leaf; }
  size_t WriteProof(uint8_t* file_ptr, size_t buf_index, uint32_t proof_type);
  static size_t ProofSize(size_t arity, size_t levels, uint32_t proof_type);

  virtual void GenInclusionPath(uint64_t challenge,
                                node_t* first_level = nullptr);
 protected:
  bool PerformFirstLevels(uint64_t challenge, node_t* first_level,
                          size_t* indices);

  // The index array will be filled with which side of the input the
  //  challenge node to prove is located on all the way up the tree.
  void GetTreePaths(size_t* indices, uint64_t challenge);

  size_t      arity_;
  size_t      levels_;
  node_t**    tree_bufs_;
  size_t      tree_bufs_len_;
  size_t      discard_rows_;
  node_t*     root_;
  node_t*     leaf_;
  node_t*     path_buf_; // Used for rebuilding trees if needed
  std::vector<PathElement*> path_; // levels number of PathElements
};

TreeProof::TreeProof(size_t arity, size_t levels,
                     node_t** tree_bufs, size_t tree_bufs_len = 1,
                     size_t discard_rows = 0) :
  arity_(arity),
  levels_(levels),
  tree_bufs_(tree_bufs),
  tree_bufs_len_(tree_bufs_len),
  discard_rows_(discard_rows)
{
  path_.reserve(levels);

  if (discard_rows > 0) {
    path_buf_ = new node_t[discard_rows * (arity - 1)];
  } else {
    path_buf_ = nullptr;
  }
}

TreeProof::~TreeProof() {
  if (path_buf_ != nullptr) {
    delete path_buf_;
  }

  for (size_t l = 0; l < levels_; ++l) {
    delete path_[l];
  }
}

size_t TreeProof::ProofSize(size_t arity, size_t levels, uint32_t proof_type) {
  size_t proof_size = 4;  // proof type u32
  proof_size += sizeof(node_t);       // root
  proof_size += sizeof(node_t);       // leaf

  proof_size += 8;        // base size u64
  proof_size += (((sizeof(node_t) * (arity - 1)) + 8 + 8) * levels);  // path

  if (proof_type == 1) {
    proof_size += 8;    // sub size u64
  }

  return proof_size;
}

size_t TreeProof::WriteProof(uint8_t* file_ptr, size_t buf_index,
                             uint32_t proof_type) {
  std::memcpy(file_ptr + buf_index, &proof_type, sizeof(uint32_t));
  buf_index += sizeof(uint32_t);

  if (proof_type == 0) {
    // Root
    std::memcpy(file_ptr + buf_index, root_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Leaf
    std::memcpy(file_ptr + buf_index, leaf_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Proof size
    std::memcpy(file_ptr + buf_index, &levels_, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    // Proofs
    for (size_t i = 0; i < levels_; ++i) {
      buf_index = path_[i]->Write(file_ptr, buf_index);
    }
  } else if (proof_type == 1) {
    // Only supports specific tree of single level sub (e.g. 32G case)

    // Base proof size
    uint64_t base_proof_vec_len = levels_ - 1;
    std::memcpy(file_ptr + buf_index, &base_proof_vec_len, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    // Base proofs
    for (size_t i = 0; i < base_proof_vec_len; ++i) {
      buf_index = path_[i]->Write(file_ptr, buf_index);
    }

    // Sub proof size
    uint64_t sub_proof_vec_len = 1;
    std::memcpy(file_ptr + buf_index, &sub_proof_vec_len, sizeof(uint64_t));
    buf_index += sizeof(uint64_t);

    // Sub proof
    buf_index = path_[base_proof_vec_len]->Write(file_ptr, buf_index);

    // Root
    std::memcpy(file_ptr + buf_index, root_, sizeof(node_t));
    buf_index += sizeof(node_t);

    // Leaf
    std::memcpy(file_ptr + buf_index, leaf_, sizeof(node_t));
    buf_index += sizeof(node_t);
  }

  return buf_index;
}

/*
  Rebuilding discarded tree r rows
  Gather enough nodes around the challenge to build subtree
  First level inclusion path is nodes
  Second level inclusion path requires hashing the 7 adjacent nodes
  Third level inclusion path requires hashing two levels to get 7 adjacent
  Fourth level and above are in the tree r files

                                       O
                                  ____/|\____
                                 /    ...    \
                                O             O
           ____________________/|\__       __/|\_____________________
          /                 |                      |                 \
         O                  O                      O                  O
  / / / / \ \ \ \    / / / / \ \ \ \  ...   / / / / \ \ \ \    / / / / \ \ \ \
 O O O O   O O O O  O O O O   O O O O      O O O O   O O O O  O O O O   O O O O
 0 1 2 3   4 5 6 7  8 9 A B   C D E F ... 1F0            1F7 1F8             1FF
*/
bool TreeProof::PerformFirstLevels(uint64_t challenge,
                                   node_t* first_level,
                                   size_t* indices) {
  const size_t arity_mask = ~(arity_ - 1);
  const size_t labels     = pow(arity_, discard_rows_ + 1);
  const size_t index_mask = labels - 1;
  const size_t sec_mask   = ~((arity_ * arity_) - 1);

  size_t leaf_start     = (challenge & arity_mask) & index_mask;
  size_t leaf_idx       = indices[0];
  size_t hash_idx       = 0;

  // Set leaf from first level
  SetLeaf((node_t*)(first_level + leaf_start + leaf_idx));

  // First level labels are separate from tree buffer files
  path_.push_back(new PathElement(arity_, (uint64_t) indices[0]));
  for (size_t a = 0; a < arity_; ++a) {
    if (a != leaf_idx) {
      path_[0]->SetHash(hash_idx++, (node_t*)(first_level + leaf_start + a));
    }
  }

  // Second level needs to hash adjacent labels
  leaf_idx       = indices[1];
  path_.push_back(new PathElement(arity_, (uint64_t) indices[1]));

  Poseidon p(arity_);

  hash_idx       = 0;
  leaf_start    &= sec_mask;
  for (size_t a = 0; a < arity_; ++a) {
    if (a != leaf_idx) {
      p.Hash((uint8_t*)&(path_buf_[hash_idx]),
             (uint8_t*)&(first_level[leaf_start + (a * arity_)]));
      path_[1]->SetHash(hash_idx, &(path_buf_[hash_idx]));
      hash_idx++;
    }
  }

  if (levels_ == 2) { // 2K case
    return true;
  }

  // Third level needs to hash adjacent labels for two levels
  uint8_t p_hash_buf[arity_][sizeof(node_t)];
  path_.push_back(new PathElement(arity_, (uint64_t) indices[2]));
  hash_idx       = 0;
  leaf_start   >>= (size_t) log2(arity_ * arity_);
  for (size_t a_o = 0; a_o < arity_; ++a_o) {
    // leaf_start is the node to skip
    if (a_o != leaf_start) {
      for (size_t a_i = 0; a_i < arity_; ++a_i) {
        p.Hash(p_hash_buf[a_i], (uint8_t*)&(first_level[(a_o * arity_ * arity_)+
                                                        (a_i * arity_)]));
      }
      p.Hash((uint8_t*)&(path_buf_[hash_idx + arity_ - 1]), p_hash_buf[0]);
      path_[2]->SetHash(hash_idx, &(path_buf_[hash_idx + arity_ - 1]));
      hash_idx++;
    }
  }

  if (levels_ == 3) {
    return true;
  }

  return false;
}

void TreeProof::GenInclusionPath(uint64_t challenge,
                                 node_t* first_level) {
  // Get the challenge index for each level of the tree
  size_t indices[levels_];
  GetTreePaths(indices, challenge);

  size_t starting_level = 0;

  if (first_level != nullptr) {
    bool done = PerformFirstLevels(challenge, first_level, indices);
    if (done) return;
    starting_level = 3;
  }

  size_t finish_level   = levels_ - 1;
  if (tree_bufs_len_ == 1) {
    finish_level   = levels_;
  }

  const size_t arity_mask = ~(arity_ - 1);
  const size_t arity_lg = (size_t) log2(arity_);
  const size_t leaves = pow(2, levels_ * arity_lg);
  const size_t file_leaves = (size_t) (leaves / tree_bufs_len_);
  const size_t file_shift = (size_t) log2(file_leaves);
  const size_t tree_idx_mask = file_leaves - 1;
  size_t start_level_size  = file_leaves;

  if (first_level != nullptr) {
    size_t act_file_leaves = pow(2, (levels_ - (discard_rows_ + 1)) * arity_lg);
    start_level_size  = (size_t) (act_file_leaves / tree_bufs_len_);
  }

  const size_t buf_idx = challenge >> file_shift;
  size_t cur_level_size = start_level_size;
  size_t add_level_size = 0;
  size_t leaf_idx;
  size_t hash_idx;
  size_t leaf_start;

  for (size_t l = starting_level; l < finish_level; ++l) {
    leaf_idx         = indices[l];
    leaf_start       = challenge & tree_idx_mask;
    leaf_start     >>= (l * arity_lg);
    leaf_start      &= arity_mask;
    leaf_start      += add_level_size;
    add_level_size  += cur_level_size;
    cur_level_size >>= arity_lg;

    if (l == 0) {
      SetLeaf((node_t*)(tree_bufs_[buf_idx] + leaf_start + leaf_idx));
    }

    path_.push_back(new PathElement(arity_, (uint64_t)leaf_idx));
    hash_idx       = 0;
    for (size_t a = 0; a < arity_; ++a) {
      if (a != leaf_idx) {
        path_[l]->SetHash(hash_idx++,
                          (node_t*)(tree_bufs_[buf_idx] + leaf_start + a));
      }
    }
  }

  if (tree_bufs_len_ == 1) {
    return;
  }

  leaf_idx         = indices[levels_ - 1];
  path_.push_back(new PathElement(arity_, (uint64_t)leaf_idx));
  hash_idx       = 0;
  for (size_t a = 0; a < arity_; ++a) {
    if (a != leaf_idx) {
      path_[levels_ - 1]->SetHash(hash_idx++,
                                  (node_t*)(tree_bufs_[a] + add_level_size));
    }
  }
}

void TreeProof::GetTreePaths(size_t* indices, uint64_t challenge) {
  size_t arity_lg   = log2(arity_);
  size_t arity_mask = arity_ - 1;

  for (size_t i = 0; i < levels_; ++i) {
    indices[i] = challenge & arity_mask;
    challenge >>= arity_lg;
  }
}

class TreeDCCProof : public TreeProof {
 public:
  TreeDCCProof(size_t arity, size_t levels,
               node_t** tree_bufs, size_t num_tree_bufs,
               size_t discard_rows) :
    TreeProof(arity, levels, tree_bufs, num_tree_bufs, discard_rows) {
      // TODO: for 64GB would need to access the next layer. CC_TREE_D_NODE_VALUES
      // would need to be filled in.
      assert (levels <= 31);

      SetRoot((node_t*)(CC_TREE_D_NODE_VALUES[levels]));
      SetLeaf((node_t*)(CC_TREE_D_NODE_VALUES[0]));
    }

  void GenInclusionPath(size_t challenge, node_t* first_level);
};

void TreeDCCProof::GenInclusionPath(uint64_t challenge,
                                    node_t* first_level) {
  size_t comm_d_indices[levels_];
  GetTreePaths(comm_d_indices, challenge);

  for (size_t l = 0; l < levels_; ++l) {
    path_.push_back(new PathElement(arity_, (uint64_t) comm_d_indices[l]));
    path_[l]->SetHash(0, (node_t*)(first_level + l));
  }
}

#endif // __TREE_PROOF_HPP__


----------------
THEN I have my Go types

package proof

// This file contains some type definitions from
// - https://github.com/filecoin-project/rust-fil-proofs/tree/master/storage-proofs-core/src/merkle
// - https://github.com/filecoin-project/rust-fil-proofs/tree/master/storage-proofs-porep/src/stacked/vanilla
// - https://github.com/filecoin-project/rust-filecoin-proofs-api/tree/master/src

// core

type Commitment [32]byte
type Ticket [32]byte

type StringRegisteredProofType string // e.g. "StackedDrg2KiBV1"

type HasherDomain = any

type Sha256Domain [32]byte

type PoseidonDomain [32]byte // Fr

/*
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct MerkleProof<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity = U0,
    TopTreeArity: PoseidonArity = U0,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    data: ProofData<H, BaseArity, SubTreeArity, TopTreeArity>,
}
*/

type MerkleProof[H HasherDomain] struct {
	Data ProofData[H] `json:"data"`
}

/*
#[derive(Debug, Clone, Serialize, Deserialize)]
enum ProofData<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity,
    TopTreeArity: PoseidonArity,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Single(SingleProof<H, BaseArity>),
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Sub(SubProof<H, BaseArity, SubTreeArity>),
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Top(TopProof<H, BaseArity, SubTreeArity, TopTreeArity>),
}
*/

type ProofData[H HasherDomain] struct {
	Single *SingleProof[H] `json:"Single,omitempty"`
	Sub    *SubProof[H]    `json:"Sub,omitempty"`
	Top    *TopProof[H]    `json:"Top,omitempty"`
}

/*
struct SingleProof<H: Hasher, Arity: PoseidonArity> {
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
    /// The path from leaf to root.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    path: InclusionPath<H, Arity>,
}
*/

type SingleProof[H HasherDomain] struct {
	Root H                `json:"root"`
	Leaf H                `json:"leaf"`
	Path InclusionPath[H] `json:"path"`
}

/*
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
struct SubProof<H: Hasher, BaseArity: PoseidonArity, SubTreeArity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    base_proof: InclusionPath<H, BaseArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    sub_proof: InclusionPath<H, SubTreeArity>,
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
}

*/

type SubProof[H HasherDomain] struct {
	BaseProof InclusionPath[H] `json:"base_proof"`
	SubProof  InclusionPath[H] `json:"sub_proof"`
	Root      H                `json:"root"`
	Leaf      H                `json:"leaf"`
}

/*
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
struct TopProof<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity,
    TopTreeArity: PoseidonArity,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    base_proof: InclusionPath<H, BaseArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    sub_proof: InclusionPath<H, SubTreeArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    top_proof: InclusionPath<H, TopTreeArity>,
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
}
*/

type TopProof[H HasherDomain] struct {
	BaseProof InclusionPath[H] `json:"base_proof"`
	SubProof  InclusionPath[H] `json:"sub_proof"`
	TopProof  InclusionPath[H] `json:"top_proof"`

	Root H `json:"root"`
	Leaf H `json:"leaf"`
}

/*
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct InclusionPath<H: Hasher, Arity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    path: Vec<PathElement<H, Arity>>,
}
*/

type InclusionPath[H HasherDomain] struct {
	Path []PathElement[H] `json:"path"`
}

/*
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct PathElement<H: Hasher, Arity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    hashes: Vec<H::Domain>,
    index: usize,
    #[serde(skip)]
    _arity: PhantomData<Arity>,
}
*/

type PathElement[H HasherDomain] struct {
	Hashes []H    `json:"hashes"`
	Index  uint64 `json:"index"`
}

// porep

type Label struct {
	ID            string `json:"id"`
	Path          string `json:"path"`
	RowsToDiscard int    `json:"rows_to_discard"`
	Size          int    `json:"size"`
}

type Labels struct {
	H      any     `json:"_h"` // todo ?
	Labels []Label `json:"labels"`
}

type PreCommit1OutRaw struct {
	LotusSealRand []byte `json:"_lotus_SealRandomness"`

	CommD           Commitment                           `json:"comm_d"`
	Config          Label                                `json:"config"`
	Labels          map[StringRegisteredProofType]Labels `json:"labels"`
	RegisteredProof StringRegisteredProofType            `json:"registered_proof"`
}

/* Commit1OutRaw maps to:
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SealCommitPhase1Output {
    pub registered_proof: RegisteredSealProof,
    pub vanilla_proofs: VanillaSealProof,
    pub comm_r: Commitment,
    pub comm_d: Commitment,
    pub replica_id: <filecoin_proofs_v1::constants::DefaultTreeHasher as Hasher>::Domain,
    pub seed: Ticket,
    pub ticket: Ticket,
}
*/

type Commit1OutRaw struct {
	CommD           Commitment                `json:"comm_d"`
	CommR           Commitment                `json:"comm_r"`
	RegisteredProof StringRegisteredProofType `json:"registered_proof"`
	ReplicaID       Commitment                `json:"replica_id"`
	Seed            Ticket                    `json:"seed"`
	Ticket          Ticket                    `json:"ticket"`

	// ProofType -> [partitions] -> [challenge_index?] -> Proof
	VanillaProofs map[StringRegisteredProofType][][]VanillaStackedProof `json:"vanilla_proofs"`
}

/*
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum VanillaSealProof {
    StackedDrg2KiBV1(Vec<Vec<RawVanillaSealProof<SectorShape2KiB>>>),
    StackedDrg8MiBV1(Vec<Vec<RawVanillaSealProof<SectorShape8MiB>>>),
    StackedDrg512MiBV1(Vec<Vec<RawVanillaSealProof<SectorShape512MiB>>>),
    StackedDrg32GiBV1(Vec<Vec<RawVanillaSealProof<SectorShape32GiB>>>),
    StackedDrg64GiBV1(Vec<Vec<RawVanillaSealProof<SectorShape64GiB>>>),
}

//VanillaSealProof as RawVanillaSealProof
pub type VanillaSealProof<Tree> = stacked::Proof<Tree, DefaultPieceHasher>;

#[derive(Debug, Serialize, Deserialize)]
pub struct Proof<Tree: MerkleTreeTrait, G: Hasher> {
    #[serde(bound(
        serialize = "MerkleProof<G, U2>: Serialize",
        deserialize = "MerkleProof<G, U2>: Deserialize<'de>"
    ))]
    pub comm_d_proofs: MerkleProof<G, U2>,
    #[serde(bound(
        serialize = "MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>: Serialize",
        deserialize = "MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>: Deserialize<'de>"
    ))]
    pub comm_r_last_proof:
        MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    #[serde(bound(
        serialize = "ReplicaColumnProof<MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,>: Serialize",
        deserialize = "ReplicaColumnProof<MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>: Deserialize<'de>"
    ))]
    pub replica_column_proofs: ReplicaColumnProof<
        MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    >,
    #[serde(bound(
        serialize = "LabelingProof<Tree::Hasher>: Serialize",
        deserialize = "LabelingProof<Tree::Hasher>: Deserialize<'de>"
    ))]
    /// Indexed by layer in 1..layers.
    pub labeling_proofs: Vec<LabelingProof<Tree::Hasher>>,
    #[serde(bound(
        serialize = "EncodingProof<Tree::Hasher>: Serialize",
        deserialize = "EncodingProof<Tree::Hasher>: Deserialize<'de>"
    ))]
    pub encoding_proof: EncodingProof<Tree::Hasher>,
}

*/

type VanillaStackedProof struct {
	CommDProofs    MerkleProof[Sha256Domain]   `json:"comm_d_proofs"`
	CommRLastProof MerkleProof[PoseidonDomain] `json:"comm_r_last_proof"`

	ReplicaColumnProofs ReplicaColumnProof[PoseidonDomain] `json:"replica_column_proofs"`
	LabelingProofs      []LabelingProof[PoseidonDomain]    `json:"labeling_proofs"`
	EncodingProof       EncodingProof[PoseidonDomain]      `json:"encoding_proof"`
}

/*
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReplicaColumnProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub c_x: ColumnProof<Proof>,
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub drg_parents: Vec<ColumnProof<Proof>>,
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub exp_parents: Vec<ColumnProof<Proof>>,
}
*/

type ReplicaColumnProof[H HasherDomain] struct {
	C_X        ColumnProof[H]   `json:"c_x"`
	DrgParents []ColumnProof[H] `json:"drg_parents"`
	ExpParents []ColumnProof[H] `json:"exp_parents"`
}

/*
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ColumnProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "Column<Proof::Hasher>: Serialize",
        deserialize = "Column<Proof::Hasher>: Deserialize<'de>"
    ))]
    pub(crate) column: Column<Proof::Hasher>,
    #[serde(bound(
        serialize = "Proof: Serialize",
        deserialize = "Proof: DeserializeOwned"
    ))]
    pub(crate) inclusion_proof: Proof,
}
*/

type ColumnProof[H HasherDomain] struct {
	Column         Column[H]      `json:"column"`
	InclusionProof MerkleProof[H] `json:"inclusion_proof"`
}

/*
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
pub struct Column<H: Hasher> {
    pub(crate) index: u32,
    pub(crate) rows: Vec<H::Domain>,
    _h: PhantomData<H>,
}
*/

type Column[H HasherDomain] struct {
	Index uint32 `json:"index"`
	Rows  []H    `json:"rows"`
	H     any    `json:"_h"`
}

/*
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LabelingProof<H: Hasher> {
    pub(crate) parents: Vec<H::Domain>,
    pub(crate) layer_index: u32,
    pub(crate) node: u64,
    #[serde(skip)]
    _h: PhantomData<H>,
}
*/

type LabelingProof[H HasherDomain] struct {
	Parents    []H    `json:"parents"`
	LayerIndex uint32 `json:"layer_index"`
	Node       uint64 `json:"node"`
	//H          any    `json:"_h"`
}

/*
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EncodingProof<H: Hasher> {
    pub(crate) parents: Vec<H::Domain>,
    pub(crate) layer_index: u32,
    pub(crate) node: u64,
    #[serde(skip)]
    _h: PhantomData<H>,
}
*/

type EncodingProof[H HasherDomain] struct {
	Parents    []H    `json:"parents"`
	LayerIndex uint32 `json:"layer_index"`
	Node       uint64 `json:"node"`
	//H          any    `json:"_h"`
}

const NODE_SIZE = 32

// SectorNodes is sector size as node count
type SectorNodes uint64


Your first task it to write down in increasing levels of details what dependencies there are between types
Then to write Go decoders for the bincoded data so that I can gave a Go struct populated from the C1 file

