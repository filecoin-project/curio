# cuzk daemon configuration
#
# Copy to /data/zk/cuzk.toml or pass via --config flag.
# All fields have sensible defaults — this file only needs to
# contain values you want to override.

[daemon]
# Listen address. TCP or Unix domain socket.
# TCP:   "0.0.0.0:9820"
# UDS:   "unix:///run/curio/cuzk.sock"
listen = "0.0.0.0:9820"

[srs]
# Directory containing Filecoin proof parameter files (.params, .vk).
# Must contain the relevant v28-*.params files for the proof types you run.
# Download with: curio fetch-params 32
param_cache = "/data/zk/params"

# SRS entries to pre-warm at daemon startup.
# This sets the environment so the first proof call per circuit type
# populates GROTH_PARAM_MEMORY_CACHE automatically.
# Values: "porep-32g", "wpost-32g", "winning-32g", "snap-32g"
preload = ["porep-32g"]

[memory]
# Maximum CUDA pinned memory budget for SRS residency.
# Phase 1+: controls how much SRS data is kept in pinned memory.
pinned_budget = "50GiB"

# Maximum working memory for proof operations.
working_memory_budget = "80GiB"

[gpus]
# GPU ordinals to use. Empty = auto-detect all GPUs.
# Example: [0, 1] to use only the first two GPUs.
devices = []

[scheduler]
# Max proofs to batch into a single GPU invocation (same circuit type).
#
# Phase 3: Cross-sector batching for PoRep C2 and SnapDeals.
# When multiple same-type proof requests arrive, the engine accumulates
# them into a batch and processes all sectors in a single synthesis + GPU
# pass. This amortizes fixed GPU costs and improves SM utilization.
#
# Memory impact (PoRep 32G, batch synthesis — all partitions at once):
#   batch=1: ~136 GiB intermediate (10 circuits)    → needs 256+ GiB RAM
#   batch=2: ~272 GiB intermediate (20 circuits)    → needs 384+ GiB RAM
#   batch=3: ~408 GiB intermediate (30 circuits)    → needs 512+ GiB RAM
#
# Throughput improvement (approximate, PoRep C2):
#   batch=1: baseline (Phase 2)
#   batch=2: ~1.5x throughput (amortize GPU fixed costs)
#   batch=3: ~2.0x throughput
#
# Set to 1 to disable batching (Phase 2 behavior).
# Set to 2-3 on large-memory machines for higher throughput.
# WinningPoSt and WindowPoSt bypass batching regardless of this setting.
max_batch_size = 1

# Max time (ms) to wait for batch to fill before flushing.
# When a batchable proof request arrives and the batch is not yet full,
# the engine waits up to this duration for more same-type requests.
# Set to 0 to flush immediately (lower latency, less batching).
# Set to 30000-60000 for proofshare nodes with steady workload.
max_batch_wait_ms = 10000

# Reorder NORMAL-priority queue to group by circuit type.
# This reduces SRS context switches on GPUs with limited VRAM.
sort_by_type = true

[synthesis]
# CPU threads for circuit synthesis. 0 = auto (num_cpus / 2).
# PoRep 32G synthesis uses ~140+ threads effectively.
threads = 0

[pipeline]
# Enable pipelined synthesis → GPU proving (Phase 2).
# When enabled, a dedicated synthesis task pre-synthesizes proofs on CPU
# and feeds them to GPU workers via a bounded channel. This allows CPU
# synthesis of proof N+1 to overlap with GPU proving of proof N:
#
#   Synthesis:  [=== proof N ===][=== proof N+1 ===][=== proof N+2 ===]
#   GPU:                         [=== proof N ===]  [=== proof N+1 ===]
#
# Steady-state throughput = max(synth_time, gpu_time) per proof.
# For PoRep 32G: ~55s/proof (synthesis-bound) vs ~91s sequential.
#
# When disabled, falls back to monolithic Phase 1 proving (no overlap).
enabled = true

# Max pre-synthesized proofs buffered between synthesis and GPU stages.
# Controls memory backpressure — each in-flight PoRep 32G proof is ~136 GiB
# of intermediate state (10 partitions × ~13.6 GiB each).
#   1 = one proof pre-synthesized (recommended for PoRep on 512+ GiB machines)
#   2+ = more aggressive lookahead (only for PoSt which has small state)
# The synthesis task blocks when the channel is full, preventing OOM.
synthesis_lookahead = 1

# Number of concurrent CPU synthesis tasks.
#
# When synthesis takes longer than GPU proving (e.g. 39s synth vs 27s GPU),
# the GPU idles for ~12s between proofs with a single synthesis task.
# With 2 concurrent synthesis tasks, the GPU can be kept fully saturated.
#
#   1 = sequential synthesis (default, lower memory)
#   2 = recommended for single-GPU machines with >=400 GiB RAM
#   N = N concurrent syntheses (each PoRep 32G synth uses ~136 GiB)
#
# Setting this > 1 subsumes the benefit of cross-sector batching
# (max_batch_size > 1) for throughput, while using the same total memory.
synthesis_concurrency = 1

[logging]
# Log level: trace, debug, info, warn, error
# Can also be overridden via RUST_LOG env var.
level = "info"

# Log format: unset for human-readable, "json" for structured.
# format = "json"
